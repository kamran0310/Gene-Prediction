{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rvllzD62ztc",
    "outputId": "fe805ef1-2253-4d3f-b80b-3b27be576de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in c:\\users\\faroo\\anaconda3\\lib\\site-packages (1.81)\n",
      "Requirement already satisfied: numpy in c:\\users\\faroo\\appdata\\roaming\\python\\python39\\site-packages (from biopython) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NbkSbWsI4Nqe"
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IA6vea3ZtJw",
    "outputId": "f8634cb3-7224-4bdb-fd0c-a6d1bfe9735d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vibBpssSsfKi"
   },
   "source": [
    "# Section 1\n",
    "For Our dataset we need chromosome numbers along with exons, starting point of exon, endpoint of exon and the gene type (Transcript, long non-coding RNA etc). We have an annotated gtf file already. We just need to extract the requisite data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tguIXOpip-P_",
    "outputId": "f60955e0-c445-4936-9fba-787c0ec2801c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exons: 1643237\n"
     ]
    }
   ],
   "source": [
    "exon_count = 0\n",
    "\n",
    "with open('D:/kamran/gencode.v42.annotation.gtf/gencode.v42.annotation.gtf', 'r') as gtf_file:\n",
    "    for line in gtf_file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        fields = line.strip().split('\\t')\n",
    "        if fields[2] == 'exon':\n",
    "            exon_count += 1\n",
    "\n",
    "print('Number of exons:', exon_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QrkouvOTVDlR"
   },
   "outputs": [],
   "source": [
    "# Step 1: Parse GTF file and extract relevant information\n",
    "gtf_file = open('D:/kamran/gencode.v42.annotation.gtf/gencode.v42.annotation.gtf', 'r')\n",
    "# Create a dictionary to map chromosome names\n",
    "chrom_mapping = {\n",
    "    'chr1': '1',\n",
    "    'chr2': '2',\n",
    "    'chr3': '3',\n",
    "    'chr4': '4',\n",
    "    'chr5': '5',\n",
    "    'chr6': '6',\n",
    "    'chr7': '7',\n",
    "    'chr8': '8',\n",
    "    'chr9': '9',\n",
    "    'chr10': '10',\n",
    "    'chr11': '11',\n",
    "    'chr12': '12',\n",
    "    'chr13': '13',\n",
    "    'chr14': '14',\n",
    "    'chr15': '15',\n",
    "    'chr16': '16',\n",
    "    'chr17': '17',\n",
    "    'chr18': '18',\n",
    "    'chr19': '19',\n",
    "    'chr20': '20',\n",
    "    'chr21': '21',\n",
    "    'chr22': '22',\n",
    "    'chrX': 'X',\n",
    "    'chrY': 'Y',\n",
    "    'chrM': 'MT'\n",
    "}\n",
    "data = []\n",
    "reader = csv.reader(gtf_file, delimiter='\\t')\n",
    "for i in range(5):\n",
    "  next(reader)\n",
    "# Loop through GTF file and replace chromosome names\n",
    "for row in reader:\n",
    "    # Get chromosome name\n",
    "    chrom = row[0]\n",
    "    # Check if chromosome name needs to be mapped\n",
    "    if chrom in chrom_mapping:\n",
    "        # Map chromosome name\n",
    "        chrom = chrom_mapping[chrom]\n",
    "        # Update row with mapped chromosome name\n",
    "        row[0] = chrom\n",
    "\n",
    "    if row[2] == 'exon':\n",
    "      chrom = row[0]\n",
    "      start = int(row[3])\n",
    "      end = int(row[4])\n",
    "      gene_type = row[8].split(';')[2].split()[1].strip('\"')\n",
    "      data.append({'chrom': chrom, 'start': start, 'end': end, 'gene_type': gene_type})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jl99VTGJ337K",
    "outputId": "90ad4db3-695b-4828-9b3b-36e4ac837910"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chrom': '1', 'start': 12613, 'end': 12721, 'gene_type': 'lncRNA'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CwiHF5dQVO14"
   },
   "outputs": [],
   "source": [
    "# # Step 2: Parse FASTA file and extract DNA sequence for relevant regions\n",
    "# fasta_file = open('/content/drive/My Drive/Homo_sapiens.GRCh38.dna.primary_assembly.fa', 'r')\n",
    "# seq_dict = {}\n",
    "# current_chrom = ''\n",
    "# current_seq = ''\n",
    "# for line in fasta_file:\n",
    "#   if line.startswith('>'):\n",
    "#       if current_chrom != '':\n",
    "#           seq_dict[current_chrom] = current_seq\n",
    "#       current_chrom = line[1:].split()[0].strip()\n",
    "#       current_seq = ''\n",
    "#   else:\n",
    "#       current_seq += line.strip()\n",
    "# seq_dict[current_chrom] = current_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "fasta_file_path = 'D:/kamran/Homo_sapiens.GRCh38.dna.primary_assembly.fa/Homo_sapiens.GRCh38.dna.primary_assembly.fa'\n",
    "# Using Biopython's SeqIO to efficiently read the fasta file and create the sequence dictionary\n",
    "seq_dict = {}\n",
    "for record in SeqIO.parse(fasta_file_path, 'fasta'):\n",
    "    seq_dict[record.id] = str(record.seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6TPll92zvyc",
    "outputId": "66038e4e-3e94-4fc4-a09e-467063c5d9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '3', '4', '5', '6', '7', '8', '9', 'MT', 'X', 'Y', 'KI270728.1', 'KI270727.1', 'KI270442.1', 'KI270729.1', 'GL000225.1', 'KI270743.1', 'GL000008.2', 'GL000009.2', 'KI270747.1', 'KI270722.1', 'GL000194.1', 'KI270742.1', 'GL000205.2', 'GL000195.1', 'KI270736.1', 'KI270733.1', 'GL000224.1', 'GL000219.1', 'KI270719.1', 'GL000216.2', 'KI270712.1', 'KI270706.1', 'KI270725.1', 'KI270744.1', 'KI270734.1', 'GL000213.1', 'GL000220.1', 'KI270715.1', 'GL000218.1', 'KI270749.1', 'KI270741.1', 'GL000221.1', 'KI270716.1', 'KI270731.1', 'KI270751.1', 'KI270750.1', 'KI270519.1', 'GL000214.1', 'KI270708.1', 'KI270730.1', 'KI270438.1', 'KI270737.1', 'KI270721.1', 'KI270738.1', 'KI270748.1', 'KI270435.1', 'GL000208.1', 'KI270538.1', 'KI270756.1', 'KI270739.1', 'KI270757.1', 'KI270709.1', 'KI270746.1', 'KI270753.1', 'KI270589.1', 'KI270726.1', 'KI270735.1', 'KI270711.1', 'KI270745.1', 'KI270714.1', 'KI270732.1', 'KI270713.1', 'KI270754.1', 'KI270710.1', 'KI270717.1', 'KI270724.1', 'KI270720.1', 'KI270723.1', 'KI270718.1', 'KI270317.1', 'KI270740.1', 'KI270755.1', 'KI270707.1', 'KI270579.1', 'KI270752.1', 'KI270512.1', 'KI270322.1', 'GL000226.1', 'KI270311.1', 'KI270366.1', 'KI270511.1', 'KI270448.1', 'KI270521.1', 'KI270581.1', 'KI270582.1', 'KI270515.1', 'KI270588.1', 'KI270591.1', 'KI270522.1', 'KI270507.1', 'KI270590.1', 'KI270584.1', 'KI270320.1', 'KI270382.1', 'KI270468.1', 'KI270467.1', 'KI270362.1', 'KI270517.1', 'KI270593.1', 'KI270528.1', 'KI270587.1', 'KI270364.1', 'KI270371.1', 'KI270333.1', 'KI270374.1', 'KI270411.1', 'KI270414.1', 'KI270510.1', 'KI270390.1', 'KI270375.1', 'KI270420.1', 'KI270509.1', 'KI270315.1', 'KI270302.1', 'KI270518.1', 'KI270530.1', 'KI270304.1', 'KI270418.1', 'KI270424.1', 'KI270417.1', 'KI270508.1', 'KI270303.1', 'KI270381.1', 'KI270529.1', 'KI270425.1', 'KI270396.1', 'KI270363.1', 'KI270386.1', 'KI270465.1', 'KI270383.1', 'KI270384.1', 'KI270330.1', 'KI270372.1', 'KI270548.1', 'KI270580.1', 'KI270387.1', 'KI270391.1', 'KI270305.1', 'KI270373.1', 'KI270422.1', 'KI270316.1', 'KI270340.1', 'KI270338.1', 'KI270583.1', 'KI270334.1', 'KI270429.1', 'KI270393.1', 'KI270516.1', 'KI270389.1', 'KI270466.1', 'KI270388.1', 'KI270544.1', 'KI270310.1', 'KI270412.1', 'KI270395.1', 'KI270376.1', 'KI270337.1', 'KI270335.1', 'KI270378.1', 'KI270379.1', 'KI270329.1', 'KI270419.1', 'KI270336.1', 'KI270312.1', 'KI270539.1', 'KI270385.1', 'KI270423.1', 'KI270392.1', 'KI270394.1'])\n"
     ]
    }
   ],
   "source": [
    "print(seq_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pXZLi7Gk4Cm",
    "outputId": "5e387352-f423-4261-f348-cdb1bb8c3af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8gTRYTetxq1",
    "outputId": "319edb1a-becf-44d7-d6e7-92a33d0baec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chrom': '1', 'start': 12613, 'end': 12721, 'gene_type': 'lncRNA'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3SJnEJw6UEJH"
   },
   "outputs": [],
   "source": [
    "# Step 3: Combine information from GTF and FASTA files\n",
    "for record in data:\n",
    "  chrom = record['chrom']\n",
    "  start = record['start']\n",
    "  end = record['end']\n",
    "  gene_type = record['gene_type']\n",
    "  seq = seq_dict[chrom][start-1:end]\n",
    "  record['sequence'] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFCAZSuVt2en",
    "outputId": "af1b4744-7c8d-452c-b0dc-0112e7a86472"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chrom': '1',\n",
       " 'start': 12613,\n",
       " 'end': 12721,\n",
       " 'gene_type': 'lncRNA',\n",
       " 'sequence': 'GTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAG'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v8q5pCr87A3x"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Randomly sample 200000 rows from data dictionary\n",
    "#small_data = random.sample(data, 200000)\n",
    "\n",
    "# Print the length of the subset dictionary\n",
    "#print(len(small_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2C9KhWv2377N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1iGYohrHCRNz",
    "outputId": "e63cf0cc-0514-47d1-88bb-80e9e4c284a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11869</td>\n",
       "      <td>12227</td>\n",
       "      <td>lncRNA</td>\n",
       "      <td>GTTAACTTGCCGTCAGCCTTTTCTTTGACCTCTTCTTTCTGTTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12613</td>\n",
       "      <td>12721</td>\n",
       "      <td>lncRNA</td>\n",
       "      <td>GTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13221</td>\n",
       "      <td>14409</td>\n",
       "      <td>lncRNA</td>\n",
       "      <td>GCAGGGCCATCAGGCACCAAAGGGATTCTGCCAGCATAGTGCTCCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12010</td>\n",
       "      <td>12057</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>GTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGCAAGCTGAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12179</td>\n",
       "      <td>12227</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>TTGGAGGAAAGATGAGTGAGAGCATCAACTTCTCTCACAACCTAGGCCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom  start    end                           gene_type  \\\n",
       "0     1  11869  12227                              lncRNA   \n",
       "1     1  12613  12721                              lncRNA   \n",
       "2     1  13221  14409                              lncRNA   \n",
       "3     1  12010  12057  transcribed_unprocessed_pseudogene   \n",
       "4     1  12179  12227  transcribed_unprocessed_pseudogene   \n",
       "\n",
       "                                            sequence  \n",
       "0  GTTAACTTGCCGTCAGCCTTTTCTTTGACCTCTTCTTTCTGTTCAT...  \n",
       "1  GTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCA...  \n",
       "2  GCAGGGCCATCAGGCACCAAAGGGATTCTGCCAGCATAGTGCTCCT...  \n",
       "3   GTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGCAAGCTGAG  \n",
       "4  TTGGAGGAAAGATGAGTGAGAGCATCAACTTCTCTCACAACCTAGGCCA  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypA0TVqppCLl",
    "outputId": "92bfdd56-ff1f-4c58-8d35-a28c26c221e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  40\n"
     ]
    }
   ],
   "source": [
    "#number of classes\n",
    "gene_types = set(d['gene_type'] for d in data)\n",
    "num_classes = len(gene_types)\n",
    "print(\"Number of classes: \", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fakhbgdYkyd",
    "outputId": "25a1ef94-e3ca-46c4-ff34-c9b9f37aa416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein_coding: 84.1407%\n",
      "lncRNA: 13.1681%\n",
      "processed_pseudogene: 0.7164%\n",
      "unprocessed_pseudogene: 0.476%\n",
      "transcribed_unprocessed_pseudogene: 0.3601%\n",
      "transcribed_unitary_pseudogene: 0.3315%\n",
      "transcribed_processed_pseudogene: 0.1786%\n",
      "misc_RNA: 0.1346%\n",
      "snRNA: 0.1157%\n",
      "miRNA: 0.1143%\n",
      "TEC: 0.0659%\n",
      "snoRNA: 0.0573%\n",
      "rRNA_pseudogene: 0.0302%\n",
      "unitary_pseudogene: 0.0217%\n",
      "IG_V_pseudogene: 0.0175%\n",
      "IG_V_gene: 0.0175%\n",
      "TR_V_gene: 0.0133%\n",
      "artifact: 0.0066%\n",
      "IG_C_gene: 0.006%\n",
      "TR_J_gene: 0.0048%\n",
      "TR_V_pseudogene: 0.0035%\n",
      "scaRNA: 0.003%\n",
      "rRNA: 0.0029%\n",
      "translated_unprocessed_pseudogene: 0.0029%\n",
      "IG_D_gene: 0.0023%\n",
      "pseudogene: 0.0021%\n",
      "TR_C_gene: 0.0014%\n",
      "Mt_tRNA: 0.0013%\n",
      "IG_J_gene: 0.0011%\n",
      "IG_C_pseudogene: 0.0009%\n",
      "ribozyme: 0.0005%\n",
      "sRNA: 0.0003%\n",
      "translated_processed_pseudogene: 0.0002%\n",
      "TR_D_gene: 0.0002%\n",
      "TR_J_pseudogene: 0.0002%\n",
      "IG_J_pseudogene: 0.0002%\n",
      "scRNA: 0.0001%\n",
      "vault_RNA: 0.0001%\n",
      "IG_pseudogene: 0.0001%\n",
      "Mt_rRNA: 0.0001%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get counts of each class\n",
    "class_counts = Counter(df['gene_type'])\n",
    "\n",
    "# Get class representation and sort in descending order\n",
    "class_reps = [(class_name, round(count / len(df) * 100, 4)) for class_name, count in class_counts.items()]\n",
    "class_reps_sorted = sorted(class_reps, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print representation of each class\n",
    "for class_name, class_rep in class_reps_sorted:\n",
    "    print(f\"{class_name}: {class_rep}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_OrwlNMLAVl",
    "outputId": "ae7c894e-1f37-4c51-d57d-4fda42459e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein_coding    1382631\n",
      "lncRNA             216383\n",
      "pseudogene          33925\n",
      "snRNA                4722\n",
      "Name: gene_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "  # Merge and rename the classes\n",
    "df[\"gene_type\"].replace({\n",
    "    \"processed_pseudogene\": \"pseudogene\",\n",
    "    \"unprocessed_pseudogene\": \"pseudogene\",\n",
    "    \"transcribed_unprocessed_pseudogene\": \"pseudogene\",\n",
    "    \"transcribed_unitary_pseudogene\": \"pseudogene\",\n",
    "    \"transcribed_processed_pseudogene\": \"pseudogene\",\n",
    "    \"snRNA\": \"snRNA\",\n",
    "    \"miRNA\": \"snRNA\",\n",
    "    \"snoRNA\": \"snRNA\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop the underrepresented classes\n",
    "df = df[df[\"gene_type\"].isin([\"protein_coding\", \"lncRNA\", \"pseudogene\", \"snRNA\"])]\n",
    "\n",
    "# Get the counts of each class\n",
    "class_counts = df[\"gene_type\"].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N5nMKuczY7St"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Get counts of each class\n",
    "class_counts = Counter(df['gene_type'])\n",
    "\n",
    "# Calculate class representation and put it in a DataFrame\n",
    "class_df = pd.DataFrame({'gene_type': list(class_counts.keys()),\n",
    "                         'count': list(class_counts.values())})\n",
    "class_df['percentage'] = round(class_df['count'] / len(df) * 100, 4)\n",
    "\n",
    "# Sort the DataFrame in descending order of percentage\n",
    "class_df = class_df.sort_values(by='percentage', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(class_df)\n",
    "#class_df.to_excel('class_distribution.xlsx', index=False)\n",
    "\n",
    "#from google.colab import files\n",
    "#files.download('class_distribution.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "q4Qz3GuVfdle",
    "outputId": "7c3f2519-08f7-4864-8b48-a689a547b679"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_type</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>protein_coding</td>\n",
       "      <td>1382631</td>\n",
       "      <td>84.4272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lncRNA</td>\n",
       "      <td>216383</td>\n",
       "      <td>13.2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pseudogene</td>\n",
       "      <td>33925</td>\n",
       "      <td>2.0716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snRNA</td>\n",
       "      <td>4722</td>\n",
       "      <td>0.2883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gene_type    count  percentage\n",
       "3  protein_coding  1382631     84.4272\n",
       "0          lncRNA   216383     13.2129\n",
       "1      pseudogene    33925      2.0716\n",
       "2           snRNA     4722      0.2883"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Representation of each class after merging\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vnz8VxUKyo8Y",
    "outputId": "0f1b6c60-f722-40c5-ca7c-ae0a0f83f4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest sequence: 347300\n",
      "Smallest sequence: 1\n"
     ]
    }
   ],
   "source": [
    "# initialize variables to hold largest and smallest sequences\n",
    "largest_seq = ''\n",
    "smallest_seq = ' ' * 1000  # set initial value to a long string\n",
    "\n",
    "# iterate through data and find largest and smallest sequences\n",
    "for record in data:\n",
    "    seq = record['sequence']\n",
    "    if len(seq) > len(largest_seq):\n",
    "        largest_seq = seq\n",
    "    if len(seq) < len(smallest_seq):\n",
    "        smallest_seq = seq\n",
    "\n",
    "# print results\n",
    "print('Largest sequence:', len(largest_seq))\n",
    "print('Smallest sequence:', len(smallest_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EBSxDUMmhA9T"
   },
   "outputs": [],
   "source": [
    "# take smaller dataframe for testing purposes as the whole dataframe will crash the colab.\n",
    "df = df.sample(n=200000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hNkIuJFERg6Z"
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "\n",
    "#Randomly sample 200000 rows from data dictionary\n",
    "#df = random.sample(data, 200000)\n",
    "\n",
    "# Print the length of the subset dictionary\n",
    "#print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "f63YRqRET1_F"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Define your buckets based on sequence lengths\n",
    "# buckets = [(1, 100), (101, 1000), (1001, 10000), (10001, 50000), (50001, 347300)]\n",
    "\n",
    "# # Function to assign a bucket for a given sequence length\n",
    "# def assign_bucket(length):\n",
    "#     for i, (start, end) in enumerate(buckets):\n",
    "#         if start <= length <= end:\n",
    "#             return i\n",
    "#     return len(buckets) - 1\n",
    "\n",
    "# # Prepare the data\n",
    "# sequences = df['sequence']\n",
    "# labels = df['gene_type']\n",
    "# max_length = 347300  # Maximum sequence length\n",
    "\n",
    "# # Convert labels to categorical\n",
    "# label_mapping = {label: i for i, label in enumerate(set(labels))}\n",
    "# num_classes = len(label_mapping)\n",
    "# labels = [label_mapping[label] for label in labels]\n",
    "# labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Preprocess the sequences and assign them to buckets\n",
    "# bucketed_sequences_train = [[] for _ in range(len(buckets))]\n",
    "# bucketed_labels_train = [[] for _ in range(len(buckets))]\n",
    "\n",
    "# for sequence, label in zip(X_train, y_train):\n",
    "#     sequence_length = len(sequence)\n",
    "#     bucket_index = assign_bucket(sequence_length)\n",
    "#     bucketed_sequences_train[bucket_index].append(sequence)\n",
    "#     bucketed_labels_train[bucket_index].append(label)\n",
    "\n",
    "# # Train a model for each bucket separately\n",
    "# models = []\n",
    "# for i in range(len(buckets)):\n",
    "#     sequences_bucket = bucketed_sequences_train[i]\n",
    "#     labels_bucket = bucketed_labels_train[i]\n",
    "\n",
    "#     # Convert sequences to padded sequences\n",
    "#     padded_sequences = pad_sequences(sequences_bucket, maxlen=max_length, padding='post')\n",
    "\n",
    "#     # Create and compile the model\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=256, output_dim=32, input_length=max_length))\n",
    "#     model.add(LSTM(64))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#     # Train the model\n",
    "#     model.fit(padded_sequences, np.array(labels_bucket), epochs=10, batch_size=32)\n",
    "#     models.append(model)\n",
    "\n",
    "# # Evaluate the models on the test set\n",
    "# for i, model in enumerate(models):\n",
    "#     sequences_bucket = pad_sequences(bucketed_sequences_train[i], maxlen=max_length, padding='post')\n",
    "#     loss, accuracy = model.evaluate(sequences_bucket, np.array(bucketed_labels_train[i]))\n",
    "#     print(f\"Bucket {i} - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])  # Set memory limit to 8GB\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the data\n",
    "sequences = df['sequence']\n",
    "labels = df['gene_type']\n",
    "max_length = 347300\n",
    "\n",
    "# Convert labels to integer-encoded labels\n",
    "label_mapping = {label: i for i, label in enumerate(set(labels))}\n",
    "num_classes = len(label_mapping)\n",
    "labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the sequences\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Define a data generator to yield batches of data during training\n",
    "def data_generator(X, y, batch_size, max_length):\n",
    "    while True:\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch_X = X[i:i+batch_size]\n",
    "            batch_y = y[i:i+batch_size]\n",
    "            padded_sequences = pad_sequences(batch_X, maxlen=max_length, padding='post')\n",
    "            yield padded_sequences, np.array(batch_y)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_length))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the data generator\n",
    "batch_size = 8\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "model.fit(data_generator(X_train_tokenized, y_train, batch_size, max_length), epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_padded = pad_sequences(X_test_tokenized, maxlen=max_length, padding='post')\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss5j34gK3zzE"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = df[['chrom', 'start', 'end', 'sequence']]\n",
    "# y = df['gene_type']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtcLEZbe4C1-",
    "outputId": "c46a14df-0e1f-492c-ccb6-3c2b897f8913"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # One-hot encode the chromosome feature\n",
    "# enc = OneHotEncoder(sparse=False)\n",
    "# X_train_chrom = enc.fit_transform(X_train['chrom'].values.reshape(-1, 1))\n",
    "# X_test_chrom = enc.transform(X_test['chrom'].values.reshape(-1, 1))\n",
    "\n",
    "# # Tokenize the DNA sequence feature\n",
    "# tokenizer = Tokenizer(char_level=True)\n",
    "# tokenizer.fit_on_texts(X_train['sequence'])\n",
    "# X_train_seq = tokenizer.texts_to_sequences(X_train['sequence'])\n",
    "# X_test_seq = tokenizer.texts_to_sequences(X_test['sequence'])\n",
    "\n",
    "# # Pad the DNA sequence feature to a fixed length\n",
    "# max_seq_length = 300000\n",
    "# X_train_seq = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
    "# X_test_seq = pad_sequences(X_test_seq, maxlen=max_seq_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1yLshx88asK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJpvUEAR4MNq",
    "outputId": "59e483ed-3032-45c1-ba7c-69ab35448864"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(shape=(X_train_chrom.shape[1] + max_seq_length,)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(len(df['gene_type'].unique()), activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Convert gene_type labels to one-hot encoding\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# le.fit(y_train)\n",
    "# y_train_enc = to_categorical(le.transform(y_train))\n",
    "# y_test_enc = to_categorical(le.transform(y_test))\n",
    "\n",
    "# history = model.fit(\n",
    "#     x=tf.concat([X_train_chrom, X_train_seq], axis=1),\n",
    "#     y=y_train_enc,\n",
    "#     validation_data=(tf.concat([X_test_chrom, X_test_seq], axis=1), y_test_enc),\n",
    "#     epochs=10,\n",
    "#     batch_size=32\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfUjqkcC7kNT",
    "outputId": "9b95a782-49d5-4a0c-c11c-20521d3d94cb"
   },
   "outputs": [],
   "source": [
    "# score = model.evaluate(tf.concat([X_test_chrom, X_test_seq], axis=1), y_test_enc, verbose=0)\n",
    "# print(f'Test loss: {score[0]}')\n",
    "# # print(f'Test accuracy: {score[1]}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
