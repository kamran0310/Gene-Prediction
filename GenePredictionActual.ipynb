{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rvllzD62ztc"
      },
      "outputs": [],
      "source": [
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbkSbWsI4Nqe"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IA6vea3ZtJw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vibBpssSsfKi"
      },
      "source": [
        "# Section 1\n",
        "For Our dataset we need chromosome numbers along with exons, starting point of exon, endpoint of exon and the gene type (Transcript, long non-coding RNA etc). We have an annotated gtf file already. We just need to extract the requisite data from the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tguIXOpip-P_"
      },
      "outputs": [],
      "source": [
        "exon_count = 0\n",
        "\n",
        "with open('/content/drive/My Drive/gencode.v42.annotation.gtf', 'r') as gtf_file:\n",
        "    for line in gtf_file:\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        fields = line.strip().split('\\t')\n",
        "        if fields[2] == 'exon':\n",
        "            exon_count += 1\n",
        "\n",
        "print('Number of exons:', exon_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrkouvOTVDlR"
      },
      "outputs": [],
      "source": [
        "# Step 1: Parse GTF file and extract relevant information\n",
        "gtf_file = open('/content/drive/My Drive/gencode.v42.annotation.gtf', 'r')\n",
        "# Create a dictionary to map chromosome names\n",
        "chrom_mapping = {\n",
        "    'chr1': '1',\n",
        "    'chr2': '2',\n",
        "    'chr3': '3',\n",
        "    'chr4': '4',\n",
        "    'chr5': '5',\n",
        "    'chr6': '6',\n",
        "    'chr7': '7',\n",
        "    'chr8': '8',\n",
        "    'chr9': '9',\n",
        "    'chr10': '10',\n",
        "    'chr11': '11',\n",
        "    'chr12': '12',\n",
        "    'chr13': '13',\n",
        "    'chr14': '14',\n",
        "    'chr15': '15',\n",
        "    'chr16': '16',\n",
        "    'chr17': '17',\n",
        "    'chr18': '18',\n",
        "    'chr19': '19',\n",
        "    'chr20': '20',\n",
        "    'chr21': '21',\n",
        "    'chr22': '22',\n",
        "    'chrX': 'X',\n",
        "    'chrY': 'Y',\n",
        "    'chrM': 'MT'\n",
        "}\n",
        "data = []\n",
        "reader = csv.reader(gtf_file, delimiter='\\t')\n",
        "for i in range(5):\n",
        "  next(reader)\n",
        "# Loop through GTF file and replace chromosome names\n",
        "for row in reader:\n",
        "    # Get chromosome name\n",
        "    chrom = row[0]\n",
        "    # Check if chromosome name needs to be mapped\n",
        "    if chrom in chrom_mapping:\n",
        "        # Map chromosome name\n",
        "        chrom = chrom_mapping[chrom]\n",
        "        # Update row with mapped chromosome name\n",
        "        row[0] = chrom\n",
        "\n",
        "    if row[2] == 'exon':\n",
        "      chrom = row[0]\n",
        "      start = int(row[3])\n",
        "      end = int(row[4])\n",
        "      gene_type = row[8].split(';')[2].split()[1].strip('\"')\n",
        "      data.append({'chrom': chrom, 'start': start, 'end': end, 'gene_type': gene_type})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl99VTGJ337K"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwiHF5dQVO14"
      },
      "outputs": [],
      "source": [
        "# Step 2: Parse FASTA file and extract DNA sequence for relevant regions\n",
        "fasta_file = open('/content/drive/My Drive/Homo_sapiens.GRCh38.dna.primary_assembly.fa', 'r')\n",
        "seq_dict = {}\n",
        "current_chrom = ''\n",
        "current_seq = ''\n",
        "for line in fasta_file:  \n",
        "  if line.startswith('>'):\n",
        "      if current_chrom != '':\n",
        "          seq_dict[current_chrom] = current_seq\n",
        "      current_chrom = line[1:].split()[0].strip()\n",
        "      current_seq = ''\n",
        "  else:\n",
        "      current_seq += line.strip()\n",
        "seq_dict[current_chrom] = current_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6TPll92zvyc"
      },
      "outputs": [],
      "source": [
        "print(seq_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pXZLi7Gk4Cm"
      },
      "outputs": [],
      "source": [
        "len(seq_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8gTRYTetxq1"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SJnEJw6UEJH"
      },
      "outputs": [],
      "source": [
        "# Step 3: Combine information from GTF and FASTA files\n",
        "for record in data:\n",
        "  chrom = record['chrom']\n",
        "  start = record['start']\n",
        "  end = record['end']\n",
        "  gene_type = record['gene_type']\n",
        "  seq = seq_dict[chrom][start-1:end]\n",
        "  record['sequence'] = seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFCAZSuVt2en"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8q5pCr87A3x"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "#Randomly sample 200000 rows from data dictionary\n",
        "#small_data = random.sample(data, 200000)\n",
        "\n",
        "# Print the length of the subset dictionary\n",
        "#print(len(small_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C9KhWv2377N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iGYohrHCRNz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypA0TVqppCLl"
      },
      "outputs": [],
      "source": [
        "#number of classes\n",
        "gene_types = set(d['gene_type'] for d in data)\n",
        "num_classes = len(gene_types)\n",
        "print(\"Number of classes: \", num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fakhbgdYkyd"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Get counts of each class\n",
        "class_counts = Counter(df['gene_type'])\n",
        "\n",
        "# Get class representation and sort in descending order\n",
        "class_reps = [(class_name, round(count / len(df) * 100, 4)) for class_name, count in class_counts.items()]\n",
        "class_reps_sorted = sorted(class_reps, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print representation of each class\n",
        "for class_name, class_rep in class_reps_sorted:\n",
        "    print(f\"{class_name}: {class_rep}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_OrwlNMLAVl"
      },
      "outputs": [],
      "source": [
        "# Merge and rename the classes\n",
        "df[\"gene_type\"].replace({\n",
        "    \"processed_pseudogene\": \"pseudogene\",\n",
        "    \"unprocessed_pseudogene\": \"pseudogene\",\n",
        "    \"transcribed_unprocessed_pseudogene\": \"pseudogene\",\n",
        "    \"transcribed_unitary_pseudogene\": \"pseudogene\",\n",
        "    \"transcribed_processed_pseudogene\": \"pseudogene\",\n",
        "    \"snRNA\": \"snRNA\",\n",
        "    \"miRNA\": \"snRNA\",\n",
        "    \"snoRNA\": \"snRNA\"\n",
        "}, inplace=True)\n",
        "\n",
        "# Drop the underrepresented classes\n",
        "df = df[df[\"gene_type\"].isin([\"protein_coding\", \"lncRNA\", \"pseudogene\", \"snRNA\"])]\n",
        "\n",
        "# Get the counts of each class\n",
        "class_counts = df[\"gene_type\"].value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5nMKuczY7St"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Get counts of each class\n",
        "class_counts = Counter(df['gene_type'])\n",
        "\n",
        "# Calculate class representation and put it in a DataFrame\n",
        "class_df = pd.DataFrame({'gene_type': list(class_counts.keys()),\n",
        "                         'count': list(class_counts.values())})\n",
        "class_df['percentage'] = round(class_df['count'] / len(df) * 100, 4)\n",
        "\n",
        "# Sort the DataFrame in descending order of percentage\n",
        "class_df = class_df.sort_values(by='percentage', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "#print(class_df)\n",
        "#class_df.to_excel('class_distribution.xlsx', index=False)\n",
        "\n",
        "#from google.colab import files\n",
        "#files.download('class_distribution.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Representation of each class after merging\n",
        "class_df"
      ],
      "metadata": {
        "id": "q4Qz3GuVfdle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnz8VxUKyo8Y"
      },
      "outputs": [],
      "source": [
        "# initialize variables to hold largest and smallest sequences\n",
        "largest_seq = ''\n",
        "smallest_seq = ' ' * 1000  # set initial value to a long string\n",
        "\n",
        "# iterate through data and find largest and smallest sequences\n",
        "for record in data:\n",
        "    seq = record['sequence']\n",
        "    if len(seq) > len(largest_seq):\n",
        "        largest_seq = seq\n",
        "    if len(seq) < len(smallest_seq):\n",
        "        smallest_seq = seq\n",
        "\n",
        "# print results\n",
        "print('Largest sequence:', len(largest_seq))\n",
        "print('Smallest sequence:', len(smallest_seq))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take smaller dataframe for testing purposes as the whole dataframe will crash the colab.\n",
        "df = df.sample(n=200000, random_state=42)\n"
      ],
      "metadata": {
        "id": "EBSxDUMmhA9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNkIuJFERg6Z"
      },
      "outputs": [],
      "source": [
        "#import random\n",
        "\n",
        "#Randomly sample 200000 rows from data dictionary\n",
        "#df = random.sample(data, 200000)\n",
        "\n",
        "# Print the length of the subset dictionary\n",
        "#print(len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss5j34gK3zzE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[['chrom', 'start', 'end', 'sequence']]\n",
        "y = df['gene_type']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtcLEZbe4C1-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# One-hot encode the chromosome feature\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "X_train_chrom = enc.fit_transform(X_train['chrom'].values.reshape(-1, 1))\n",
        "X_test_chrom = enc.transform(X_test['chrom'].values.reshape(-1, 1))\n",
        "\n",
        "# Tokenize the DNA sequence feature\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(X_train['sequence'])\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train['sequence'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test['sequence'])\n",
        "\n",
        "# Pad the DNA sequence feature to a fixed length\n",
        "max_seq_length = 100\n",
        "X_train_seq = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
        "X_test_seq = pad_sequences(X_test_seq, maxlen=max_seq_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E1yLshx88asK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJpvUEAR4MNq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_chrom.shape[1] + max_seq_length,)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(df['gene_type'].unique()), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Convert gene_type labels to one-hot encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train_enc = to_categorical(le.transform(y_train))\n",
        "y_test_enc = to_categorical(le.transform(y_test))\n",
        "\n",
        "history = model.fit(\n",
        "    x=tf.concat([X_train_chrom, X_train_seq], axis=1),\n",
        "    y=y_train_enc,\n",
        "    validation_data=(tf.concat([X_test_chrom, X_test_seq], axis=1), y_test_enc),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfUjqkcC7kNT"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(tf.concat([X_test_chrom, X_test_seq], axis=1), y_test_enc, verbose=0)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}